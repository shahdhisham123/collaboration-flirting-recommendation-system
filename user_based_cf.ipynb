{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39278c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Matrix Shape: (943, 1664)\n",
      "Sample (First 5 Users, First 5 Movies):\n",
      "         'Til There Was You (1997)  1-900 (1994)  101 Dalmatians (1996)  \\\n",
      "user_id                                                                   \n",
      "1                              0.0           0.0                    2.0   \n",
      "2                              0.0           0.0                    0.0   \n",
      "3                              0.0           0.0                    0.0   \n",
      "4                              0.0           0.0                    0.0   \n",
      "5                              0.0           0.0                    2.0   \n",
      "\n",
      "         12 Angry Men (1957)  187 (1997)  \n",
      "user_id                                   \n",
      "1                        5.0         0.0  \n",
      "2                        0.0         0.0  \n",
      "3                        0.0         2.0  \n",
      "4                        0.0         0.0  \n",
      "5                        0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the user-item matrix from preprocessing\n",
    "user_item_matrix = pd.read_csv(\"C:/Users/Zenab/Desktop/inn assigment/res\", index_col='user_id')\n",
    "\n",
    "print(\"User-Item Matrix Shape:\", user_item_matrix.shape)\n",
    "print(\"Sample (First 5 Users, First 5 Movies):\")\n",
    "print(user_item_matrix.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ba334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 80000 ratings\n",
      "Test set size: 20000 ratings\n"
     ]
    }
   ],
   "source": [
    "# Load the original ratings data (not the user-item matrix)\n",
    "ratings = pd.read_csv('C:/Users/Zenab/Desktop/inn assigment/ml-100k', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Define the rating scale (1-5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load data into Surprise format\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split into train-test (80-20)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "# Correct way to check sizes:\n",
    "\n",
    "print(f\"Train set size: {trainset.n_ratings} ratings\")\n",
    "print(f\"Test set size: {len(testset)} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "508fe389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Similarity Matrix Shape: (943, 943)\n",
      "Sample (First 5 Users):\n",
      "user_id         1         2         3         4         5\n",
      "user_id                                                  \n",
      "1        1.000000  0.168937  0.048388  0.064561  0.379670\n",
      "2        0.168937  1.000000  0.113393  0.179694  0.073623\n",
      "3        0.048388  0.113393  1.000000  0.349781  0.021592\n",
      "4        0.064561  0.179694  0.349781  1.000000  0.031804\n",
      "5        0.379670  0.073623  0.021592  0.031804  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between users\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "user_similarity = pd.DataFrame(\n",
    "    user_similarity,\n",
    "    index=user_item_matrix.index,\n",
    "    columns=user_item_matrix.index\n",
    ")\n",
    "\n",
    "print(\"User Similarity Matrix Shape:\", user_similarity.shape)\n",
    "print(\"Sample (First 5 Users):\")\n",
    "print(user_similarity.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_title, k=5):\n",
    "  \n",
    "    # Get similarity scores for the target user\n",
    "    sim_scores = user_similarity.loc[user_id]\n",
    "    \n",
    "    # Get ratings for the target movie\n",
    "    movie_ratings = user_item_matrix[movie_title]\n",
    "    \n",
    "    # Remove users who haven't rated the movie\n",
    "    valid_users = movie_ratings[movie_ratings > 0].index\n",
    "    sim_scores = sim_scores[valid_users]\n",
    "    \n",
    "    # Get top-K most similar users\n",
    "    top_k_users = sim_scores.sort_values(ascending=False)[1:k+1]  # Exclude self\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    weighted_sum = np.dot(\n",
    "        top_k_users.values,\n",
    "        user_item_matrix.loc[top_k_users.index, movie_title]\n",
    "    )\n",
    "    prediction = weighted_sum / top_k_users.sum()\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a57152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User 1 on 'Toy Story (1995)': 4.00\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "movie_title = \"Toy Story (1995)\"\n",
    "predicted_rating = predict_rating(user_id, movie_title, k=5)\n",
    "\n",
    "print(f\"Predicted rating for User {user_id} on '{movie_title}': {predicted_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, n=5):\n",
    "    \"\"\"\n",
    "    Recommends top-N movies a user hasn't rated yet.\n",
    "    \"\"\"\n",
    "    # Movies the user has already rated\n",
    "    rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
    "    \n",
    "    # Predict ratings for unrated movies\n",
    "    predictions = []\n",
    "    for movie in user_item_matrix.columns:\n",
    "        if movie not in rated_movies:\n",
    "            pred = predict_rating(user_id, movie)\n",
    "            predictions.append((movie, pred))\n",
    "    \n",
    "    # Sort by predicted rating\n",
    "    recommendations = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example: Get top 5 recommendations for User 1\n",
    "user_id = 1\n",
    "recommendations = recommend_movies(user_id, n=5)\n",
    "\n",
    "print(f\"Top 5 Recommendations for User {user_id}:\")\n",
    "for i, (movie, rating) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {movie} (Predicted Rating: {rating:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d20d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(testset, user_similarity, user_item_matrix, movies, k=5):\n",
    "    \n",
    "    # Create mapping dictionaries for faster lookups\n",
    "    movie_id_to_title = dict(zip(movies['item_id'], movies['title']))\n",
    "    user_mean_ratings = user_item_matrix.mean(axis=1)\n",
    "    global_mean = user_item_matrix.mean().mean()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    # Pre-compute all possible movie titles in test set\n",
    "    test_movies = {movie for _, movie, _ in testset}\n",
    "    available_movies = set(movie_id_to_title.keys())\n",
    "    \n",
    "    for user, movie, _ in testset:\n",
    "        # Skip if movie not in our training data\n",
    "        if movie not in available_movies:\n",
    "            predictions.append(global_mean)\n",
    "            continue\n",
    "            \n",
    "        movie_title = movie_id_to_title[movie]\n",
    "        \n",
    "        try:\n",
    "            # Get similar users (excluding self)\n",
    "            sim_scores = user_similarity.loc[user]\n",
    "            user_ratings = user_item_matrix[movie_title]\n",
    "            \n",
    "            # Find users who rated this movie\n",
    "            rated_users = user_ratings[user_ratings > 0].index\n",
    "            rated_users = rated_users[rated_users != user]  # Exclude self\n",
    "            \n",
    "            if len(rated_users) == 0:\n",
    "                predictions.append(user_mean_ratings.loc[user])\n",
    "                continue\n",
    "                \n",
    "            # Get top K similar users who rated this movie\n",
    "            user_sims = sim_scores[rated_users]\n",
    "            top_k_users = user_sims.nlargest(k).index\n",
    "            \n",
    "            # Calculate weighted average\n",
    "            weighted_sum = (user_item_matrix.loc[top_k_users, movie_title] * \n",
    "                          user_similarity.loc[user, top_k_users]).sum()\n",
    "            norm = user_similarity.loc[user, top_k_users].sum()\n",
    "            \n",
    "            prediction = weighted_sum / norm if norm != 0 else user_mean_ratings.loc[user]\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        except:\n",
    "            predictions.append(global_mean)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(user_id, ratings_df, movies_df, k=5, threshold=3.5):\n",
    "   \n",
    "    # Get ground truth (movies the user rated highly)\n",
    "    user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "    highly_rated = set(user_ratings[user_ratings['rating'] >= threshold]['item_id'])\n",
    "    \n",
    "    # Get recommendations (assuming recommend_movies exists)\n",
    "    recommended_movies = recommend_movies(user_id, n=k)\n",
    "    \n",
    "    # Convert recommendations to item IDs\n",
    "    recommended = []\n",
    "    for movie_title, _ in recommended_movies:\n",
    "        movie_id = movies_df[movies_df['title'] == movie_title]['item_id'].values\n",
    "        if len(movie_id) > 0:\n",
    "            recommended.append(movie_id[0])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    relevant_and_recommended = len(highly_rated.intersection(recommended))\n",
    "    precision = relevant_and_recommended / k\n",
    "    recall = relevant_and_recommended / len(highly_rated) if highly_rated else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "ratings = pd.read_csv('C:/Users/Zenab/Desktop/inn assigment/ml-100k', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "movies = pd.read_csv('C:/Users/Zenab/Desktop/inn assigment/ml-100k', sep='|', encoding='latin-1', \n",
    "                    usecols=[0, 1], names=['item_id', 'title'])\n",
    "\n",
    "# Then evaluate for a user\n",
    "precision, recall = precision_recall_at_k(\n",
    "    user_id=1,\n",
    "    ratings_df=ratings,\n",
    "    movies_df=movies,\n",
    "    k=5\n",
    ")\n",
    "print(f\"Precision@5: {precision:.2f}, Recall@5: {recall:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
